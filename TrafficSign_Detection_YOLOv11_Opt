{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10791436,"sourceType":"datasetVersion","datasetId":6696835},{"sourceId":10792052,"sourceType":"datasetVersion","datasetId":6697271}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ultralytics\n!nvidia-smi\n!pip install optuna","metadata":{"executionInfo":{"elapsed":12336,"status":"ok","timestamp":1740395396005,"user":{"displayName":"Aditya Bayhaqie","userId":"16906297684641538968"},"user_tz":-420},"id":"IdMGCuK5iics","outputId":"9c3cd1fc-194b-42e8-969c-94ffa5ccdfe2","trusted":true,"execution":{"iopub.status.busy":"2025-02-24T11:55:43.801259Z","iopub.execute_input":"2025-02-24T11:55:43.801569Z","iopub.status.idle":"2025-02-24T11:55:50.875228Z","shell.execute_reply.started":"2025-02-24T11:55:43.801544Z","shell.execute_reply":"2025-02-24T11:55:50.874295Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport random\nfrom PIL import Image\nimport cv2\nfrom ultralytics import YOLO\nfrom IPython.display import Video\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style='darkgrid')\nimport pathlib\nimport glob\nfrom tqdm.notebook import trange, tqdm\nimport warnings\nimport optuna","metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1740395396013,"user":{"displayName":"Aditya Bayhaqie","userId":"16906297684641538968"},"user_tz":-420},"id":"WXz2TvGRdoh0","trusted":true,"execution":{"iopub.status.busy":"2025-02-24T11:55:50.876960Z","iopub.execute_input":"2025-02-24T11:55:50.877345Z","iopub.status.idle":"2025-02-24T11:55:50.884173Z","shell.execute_reply.started":"2025-02-24T11:55:50.877307Z","shell.execute_reply":"2025-02-24T11:55:50.883276Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Image_dir = '/kaggle/input/indonesia-traffic-sign-dataset-yolov11/train/images'\n\nnum_samples = 9\nimage_files = os.listdir(Image_dir)\n\n# Randomly select num_samples images\nrand_images = random.sample(image_files, num_samples)\n\nfig, axes = plt.subplots(3, 3, figsize=(11, 11))\n\nfor i in range(num_samples):\n    image = rand_images[i]\n    ax = axes[i // 3, i % 3]\n    ax.imshow(plt.imread(os.path.join(Image_dir, image)))\n    ax.set_title(f'Image {i+1}')\n    ax.axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"executionInfo":{"elapsed":2878,"status":"ok","timestamp":1740395451305,"user":{"displayName":"Aditya Bayhaqie","userId":"16906297684641538968"},"user_tz":-420},"id":"KAq14NXJi8ps","outputId":"f3c54d46-ada4-440c-f190-2a02e96a9b09","trusted":true,"execution":{"iopub.status.busy":"2025-02-24T11:55:50.885731Z","iopub.execute_input":"2025-02-24T11:55:50.885996Z","iopub.status.idle":"2025-02-24T11:55:52.962750Z","shell.execute_reply.started":"2025-02-24T11:55:50.885975Z","shell.execute_reply":"2025-02-24T11:55:52.961870Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##Model-Parameter Optimization","metadata":{"id":"cRx9aHedjAX3"}},{"cell_type":"code","source":"# def yolo_objective(trial):\n#     # Sample hyperparameters\n#     lr0 = trial.suggest_float(\"lr0\", 1e-5, 1e-2, log=True)\n#     momentum = trial.suggest_float(\"momentum\", 0.85, 0.95)  # Add momentum\n#     weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 1e-3, log=True)  # Add weight decay\n#     optimizer = trial.suggest_categorical(\"optimizer\", [\"SGD\", \"Adam\"]) # Add optimizer\n#     dropout = trial.suggest_float(\"dropout\", 0.0, 0.5)\n#     batch = trial.suggest_categorical(\"batch\", [32, 64, 128])\n#     # Add augmentations\n#     fliplr = trial.suggest_categorical(\"fliplr\", [0.0, 0.5, 1.0])\n#     hsv_h = trial.suggest_float(\"hsv_h\", 0.0, 0.1)\n#     hsv_s = trial.suggest_float(\"hsv_s\", 0.0, 0.9)\n#     hsv_v = trial.suggest_float(\"hsv_v\", 0.0, 0.9)\n#     degrees = trial.suggest_float(\"degrees\", 0.0, 45.0)\n#     translate = trial.suggest_float(\"translate\", 0.0, 0.2)\n#     scale = trial.suggest_float(\"scale\", 0.5, 0.99)\n#     shear = trial.suggest_float(\"shear\", 0.0, 10.0)\n\n#     # Build and train the model\n#     model = YOLO('yolo11n.yaml').load('yolo11n.pt')\n#     results = model.train(\n#         data=\"/kaggle/input/indonesia-traffic-sign-dataset-yolov11/data.yaml\",\n#         epochs=10,\n#         imgsz=416,\n#         batch=batch,\n#         lr0=lr0,\n#         dropout=dropout,\n#         fliplr=fliplr,\n#         hsv_h=hsv_h,\n#         hsv_s=hsv_s,\n#         hsv_v=hsv_v,\n#         degrees=degrees,\n#         translate=translate,\n#         scale=scale,\n#         shear=shear,\n#         optimizer=optimizer,\n#         momentum=momentum if optimizer == \"SGD\" else 0.0,  # Conditional momentum\n#         weight_decay=weight_decay,\n#         device=0\n#     )\n\n#     print(f\"lr0: {lr0}, momentum: {momentum}, weight_decay: {weight_decay}\")  # Print variable values\n#     print(f\"optimizer: {optimizer}, dropout: {dropout}, batch: {batch}\")\n\n#     # Return the metric to optimize (e.g., mAP@0.5)\n#     return results.results_dict[\"metrics/mAP50(B)\"]\n\n# study = optuna.create_study(direction=\"maximize\")  # Maximize mAP@0.5\n# study.optimize(yolo_objective, n_trials=20)  # Run 100 trials\n\n\n\n# print(f'Best CV    : {study.best_params}')\n# print(f'Best Score : {study.best_value}')\n\n\n# Best CV    : {'lr0': 0.00847696530576254, 'momentum': 0.9161487200959822, 'weight_decay': 8.940040440220955e-05, 'optimizer': 'SGD', 'dropout': 0.2784791741928995, 'batch': 32, 'fliplr': 0.0, 'hsv_h': 0.05347859072134238, 'hsv_s': 0.29449466762305965, 'hsv_v': 0.584027983109837, 'degrees': 0.0162282968670604, 'translate': 0.05712250032606517, 'scale': 0.8652107976073655, 'shear': 3.129172129671245}\n# Best Score : 0.9917819877169816\n","metadata":{"id":"0toMCpOUig-2","executionInfo":{"status":"error","timestamp":1740395839225,"user_tz":-420,"elapsed":412,"user":{"displayName":"Aditya Bayhaqie","userId":"16906297684641538968"}},"outputId":"a4667f75-bd72-4ac0-fd01-eb799ddeec0f","trusted":true,"execution":{"iopub.status.busy":"2025-02-24T12:16:31.919450Z","iopub.execute_input":"2025-02-24T12:16:31.919849Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Use a pretrained YOLOv11n model\nmodel = YOLO(\"yolo11n.pt\")\n\n# Build from YAML and transfer weights\nFinal_model = YOLO('yolo11n.yaml').load('yolo11n.pt')\n\n# Training The Final Model\nResult_Final_model = Final_model.train(data=\"/kaggle/input/indonesia-traffic-sign-dataset-yolov11/data.yaml\",epochs=100, imgsz = 416, 'lr0': 0.00847696530576254, 'momentum': 0.9161487200959822, 'weight_decay': 8.940040440220955e-05, 'optimizer': 'SGD', 'dropout': 0.2784791741928995, 'batch': 32, 'fliplr': 0.0, 'hsv_h': 0.05347859072134238, 'hsv_s': 0.29449466762305965, 'hsv_v': 0.584027983109837, 'degrees': 0.0162282968670604, 'translate': 0.05712250032606517, 'scale': 0.8652107976073655, 'shear': 3.129172129671245, device = 0)","metadata":{"executionInfo":{"elapsed":66704,"status":"aborted","timestamp":1740395450193,"user":{"displayName":"Aditya Bayhaqie","userId":"16906297684641538968"},"user_tz":-420},"id":"rPQDURyHj8M_","trusted":true,"execution":{"iopub.status.busy":"2025-02-24T11:28:32.453212Z","iopub.status.idle":"2025-02-24T11:28:32.453562Z","shell.execute_reply":"2025-02-24T11:28:32.453386Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"list_of_metrics = [\"P_curve.png\",\"R_curve.png\",\"confusion_matrix.png\"]","metadata":{"id":"4swsylTilJPZ","executionInfo":{"status":"aborted","timestamp":1740395450199,"user_tz":-420,"elapsed":66704,"user":{"displayName":"Aditya Bayhaqie","userId":"16906297684641538968"}},"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T11:28:32.454270Z","iopub.status.idle":"2025-02-24T11:28:32.454569Z","shell.execute_reply":"2025-02-24T11:28:32.454427Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the image\nfor i in list_of_metrics:\n    image = cv2.imread(f'/kaggle/working/runs/detect/train/{i}')\n\n    # Create a larger figure\n    plt.figure(figsize=(16, 12))\n\n    # Display the image\n    plt.imshow(image)\n\n    # Show the plot\n    plt.show()","metadata":{"executionInfo":{"elapsed":66704,"status":"aborted","timestamp":1740395450202,"user":{"displayName":"Aditya Bayhaqie","userId":"16906297684641538968"},"user_tz":-420},"id":"E6nyOhJcl7C8","trusted":true,"execution":{"iopub.status.busy":"2025-02-24T11:28:32.455251Z","iopub.status.idle":"2025-02-24T11:28:32.455583Z","shell.execute_reply":"2025-02-24T11:28:32.455416Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Read the results.csv file as a pandas dataframe\nResult_Final_model = pd.read_csv('/kaggle/working/runs/detect/train/results.csv')\nResult_Final_model.columns = Result_Final_model.columns.str.strip()\n\n# Create subplots\nfig, axs = plt.subplots(nrows=5, ncols=2, figsize=(15, 15))\n\n# Plot the columns using seaborn\nsns.lineplot(x='epoch', y='train/box_loss', data=Result_Final_model, ax=axs[0,0])\nsns.lineplot(x='epoch', y='train/cls_loss', data=Result_Final_model, ax=axs[0,1])\nsns.lineplot(x='epoch', y='train/dfl_loss', data=Result_Final_model, ax=axs[1,0])\nsns.lineplot(x='epoch', y='metrics/precision(B)', data=Result_Final_model, ax=axs[1,1])\nsns.lineplot(x='epoch', y='metrics/recall(B)', data=Result_Final_model, ax=axs[2,0])\nsns.lineplot(x='epoch', y='metrics/mAP50(B)', data=Result_Final_model, ax=axs[2,1])\nsns.lineplot(x='epoch', y='metrics/mAP50-95(B)', data=Result_Final_model, ax=axs[3,0])\nsns.lineplot(x='epoch', y='val/box_loss', data=Result_Final_model, ax=axs[3,1])\nsns.lineplot(x='epoch', y='val/cls_loss', data=Result_Final_model, ax=axs[4,0])\nsns.lineplot(x='epoch', y='val/dfl_loss', data=Result_Final_model, ax=axs[4,1])\n\n# Set titles and axis labels for each subplot\naxs[0,0].set(title='Train Box Loss')\naxs[0,1].set(title='Train Class Loss')\naxs[1,0].set(title='Train DFL Loss')\naxs[1,1].set(title='Metrics Precision (B)')\naxs[2,0].set(title='Metrics Recall (B)')\naxs[2,1].set(title='Metrics mAP50 (B)')\naxs[3,0].set(title='Metrics mAP50-95 (B)')\naxs[3,1].set(title='Validation Box Loss')\naxs[4,0].set(title='Validation Class Loss')\naxs[4,1].set(title='Validation DFL Loss')\n\nplt.suptitle('Training Metrics and Loss', fontsize=24)\nplt.subplots_adjust(top=0.8)\nplt.tight_layout()\nplt.show()","metadata":{"executionInfo":{"elapsed":89,"status":"error","timestamp":1740395379478,"user":{"displayName":"Aditya Bayhaqie","userId":"16906297684641538968"},"user_tz":-420},"id":"Eto9nu6jl_N0","outputId":"16215d25-5906-4ad8-8754-a9e756ace9da"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Loading the best performing model\nValid_model = YOLO('/kaggle/working/runs/detect/train/weights/best.pt')\n\n# Evaluating the model on the testset\nmetrics = Valid_model.val(split = 'test')","metadata":{"executionInfo":{"elapsed":227,"status":"aborted","timestamp":1740395379636,"user":{"displayName":"Aditya Bayhaqie","userId":"16906297684641538968"},"user_tz":-420},"id":"L3qD_cHdmS0h"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# final results\nprint(\"precision(B): \", metrics.results_dict[\"metrics/precision(B)\"])\nprint(\"metrics/recall(B): \", metrics.results_dict[\"metrics/recall(B)\"])\nprint(\"metrics/mAP50(B): \", metrics.results_dict[\"metrics/mAP50(B)\"])\nprint(\"metrics/mAP50-95(B): \", metrics.results_dict[\"metrics/mAP50-95(B)\"])","metadata":{"executionInfo":{"elapsed":208,"status":"aborted","timestamp":1740395379644,"user":{"displayName":"Aditya Bayhaqie","userId":"16906297684641538968"},"user_tz":-420},"id":"jJ-k5X4-mQWr"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Path to the directory containing the images\nimage_dir = '/kaggle/input/indonesia-traffic-sign-dataset-yolov11/test/images'\n\n# Get a list of all image files in the directory\nimage_files = [os.path.join(image_dir, file) for file in os.listdir(image_dir) if file.endswith('.jpg')]\n\n# Randomly select 10 images from the directory\nrandom_images = random.sample(image_files, k=10)\n\nfor image_path in random_images:\n    image = cv2.imread(image_path)  # Replace with your preferred method of reading the image\n    results = Final_model.predict([image], save=True, imgsz=416, conf=0.5, iou=0.7)\n    #results.append(result)","metadata":{"executionInfo":{"elapsed":590,"status":"aborted","timestamp":1740395379662,"user":{"displayName":"Aditya Bayhaqie","userId":"16906297684641538968"},"user_tz":-420},"id":"5uNZcqzbmiFG"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# View results\nfor i in range(2,9):\n    plt.imshow(plt.imread(f'/content/runs/detect/train/image{i}.jpg'))\n    plt.show()","metadata":{"executionInfo":{"elapsed":580,"status":"aborted","timestamp":1740395379666,"user":{"displayName":"Aditya Bayhaqie","userId":"16906297684641538968"},"user_tz":-420},"id":"-CVMtf0rmttI"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport time\n\n# def limit_video_duration(input_path, output_path, duration_limit=30):\n#     \"\"\"Limits the duration of a video to a specified time.\n\n#     Args:\n#         input_path: Path to the input video file.\n#         output_path: Path to save the limited video file.\n#         duration_limit: Maximum duration of the video in seconds (default: 180 seconds).\n#     \"\"\"\n\n#     cap = cv2.VideoCapture(input_path)\n#     frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n#     frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n#     fps = int(cap.get(cv2.CAP_PROP_FPS))\n\n#     fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n#     out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\n#     start_time = time.time()\n\n#     while cap.isOpened() and (time.time() - start_time) < duration_limit:\n#         ret, frame = cap.read()\n#         if not ret:\n#             break\n\n#         out.write(frame)  # Write the frame directly without processing\n\n#     cap.release()\n#     out.release()","metadata":{"id":"HOMkmkBqVMWF","executionInfo":{"status":"aborted","timestamp":1740395379671,"user_tz":-420,"elapsed":579,"user":{"displayName":"Aditya Bayhaqie","userId":"16906297684641538968"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"input_video_path = '/kaggle/input/video-tester/test.mp4'\noutput_video_path = '/kaggle/working/limited_video.mp4'\n\nlimit_video_duration(input_video_path, output_video_path)","metadata":{"executionInfo":{"elapsed":23,"status":"error","timestamp":1740395379701,"user":{"displayName":"Aditya Bayhaqie","userId":"16906297684641538968"},"user_tz":-420},"id":"8I5pw7BKX6ap","outputId":"59f5ce95-5b81-4935-81ec-8b59a2e3104e"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def prediction_yolo_single_gpu(\n    source: str='/kaggle/working/test.mp4',\n    weights: str='/content/drive/MyDrive/CollabData/TrafficSign_YOLOv11/runs/detect/train2/weights/best.pt',\n    conf: float=0.25,\n    save: bool=True,\n    **kwargs\n    ):\n\n    model = YOLO(weights)\n\n    prediction_results = model.predict(\n        source=source,\n        conf=conf,\n        save=save,\n        **kwargs\n    )\n\n    # Path of input video after prediction\n    avi_path = '/content/runs/detect/predict/result.avi'\n\n    # Path of the output video to be compressed\n    mp4_path = \"/content/result_detection_yolov11.mp4\"\n\n    # Convert .avi to .mp4 using ffmpeg\n    os.system(f\"ffmpeg -i {avi_path} -vcodec libx264 {mp4_path}\")\n\n    return prediction_results\n\nprediction_results = prediction_yolo_single_gpu()","metadata":{"executionInfo":{"elapsed":569,"status":"aborted","timestamp":1740395379682,"user":{"displayName":"Aditya Bayhaqie","userId":"16906297684641538968"},"user_tz":-420},"id":"5-qGaoVCnQGu"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom base64 import b64encode\nfrom IPython.display import HTML, display\n\n# Path of input video after prediction\nsave_path = '/content/runs/detect/predict/result.avi'\n\n# Path of the output video to be compressed\ncompressed_path = \"/content/result_detection_yolov11.mp4\"\n\n# Kompres video menggunakan ffmpeg\nos.system(f\"ffmpeg -i {save_path} -vcodec libx264 {compressed_path}\")\n\nif os.path.exists(compressed_path):\n    # Read the compressed video\n    with open(compressed_path, \"rb\") as video_file:\n        video_data = video_file.read()\n\n    # Encode video in base64 so it can be displayed in HTML\n    data_url = \"data:video/mp4;base64,\" + b64encode(video_data).decode()\n\n    # Embed and display video on notebook\n    display(HTML(f\"\"\"\n    <video width=\"640\" height=\"480\" controls>\n          <source src=\"{data_url}\" type=\"video/mp4\">\n    </video>\n    \"\"\"))\nelse:\n    print(\"Video file not found.\")","metadata":{"id":"xnxKsEGzp7Rp","executionInfo":{"status":"ok","timestamp":1740395380594,"user_tz":-420,"elapsed":890,"user":{"displayName":"Aditya Bayhaqie","userId":"16906297684641538968"}},"outputId":"46d81535-db3d-4650-eed1-88d4072b14b1"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"4i-LZuWURPTr","executionInfo":{"status":"ok","timestamp":1740395380617,"user_tz":-420,"elapsed":6,"user":{"displayName":"Aditya Bayhaqie","userId":"16906297684641538968"}}},"outputs":[],"execution_count":null}]}